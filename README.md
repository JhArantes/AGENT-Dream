


# âš™ï¸ğŸ’¬ AI Chat API â€” FastAPI + Strands Agents + Ollama

<div align="center">

![AI Chat API](IMGs/AI_Chat_IMG.png)

**API de Chat Inteligente com Agentes Locais e Ferramentas Personalizadas**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-orange.svg)](https://ollama.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

</div>

## âœ¨ **Recursos Principais**

| Recurso | DescriÃ§Ã£o |
|---------|-----------|
| ğŸ¤– **Agente Inteligente** | Processamento de linguagem natural com raciocÃ­nio contextual |
| ğŸ§® **Ferramenta MatemÃ¡tica** | ResoluÃ§Ã£o de expressÃµes matemÃ¡ticas complexas |
| âš¡ **Baixa LatÃªncia** | Respostas rÃ¡pidas via FastAPI + Uvicorn |
| ğŸ”§ **ExtensÃ­vel** | Arquitetura modular para adiÃ§Ã£o de novas ferramentas |
| ğŸ” **Local & Privado** | ExecuÃ§Ã£o completa local sem dependÃªncia de APIs externas |
| ğŸŒ **API FastAPI** | Interface padrÃ£o para integraÃ§Ã£o com outros sistemas |

---

## ğŸ“‹ **Ãndice**

- [ğŸš€ ComeÃ§ando](#-comeÃ§ando)
  - [PrÃ©-requisitos](#prÃ©-requisitos)
  - [InstalaÃ§Ã£o](#instalaÃ§Ã£o)
- [âš™ï¸ ConfiguraÃ§Ã£o](#ï¸-configuraÃ§Ã£o)
- [ğŸ”§ Estrutura do Projeto](#-estrutura-do-projeto)
- [ğŸ“¡ Uso da API](#-uso-da-api)
  - [Endpoints DisponÃ­veis](#endpoints-disponÃ­veis)
  - [Exemplos de Uso](#exemplos-de-uso)
- [ğŸ› ï¸ Desenvolvimento](#ï¸-desenvolvimento)
  - [Adicionando Novas Ferramentas](#adicionando-novas-ferramentas)
  - [Testes](#testes)
- [ğŸ¤ Contribuindo](#-contribuindo)
- [ğŸ“„ LicenÃ§a](#-licenÃ§a)

---

## ğŸš€ **ComeÃ§ando**

### **PrÃ©-requisitos**

Antes de comeÃ§ar, certifique-se de ter instalado:

- **Python 3.10 ou superior**
- **Ollama** (para execuÃ§Ã£o local de modelos LLM)
- **Git** (para clonar o repositÃ³rio)

### **InstalaÃ§Ã£o**

#### 1. **Clone o repositÃ³rio**
```bash
git clone https://github.com/seu-usuario/ai-chat-api.git
cd ai-chat-api
```


#### 2. **Instale o Ollama**
  - Linux/macOS:
  ```bash
  curl -fsSL https://ollama.com/install.sh | sh
  ```
  - Windows: Baixe o instalador em [ollama.com](https://ollama.com)


#### 3. **Baixe um modelo LLM**
```bash
# Recomendado para iniciar:
ollama pull llama3.1:8b

# Alternativas populares:
# ollama pull mistral:7b
# ollama pull qwen2.5:7b
```

#### 4. **Configure o ambiente python**
```bash
# Crie um ambiente virtual
python -m venv venv

# Ative o ambiente virtual
# Linux/macOS:
source venv/bin/activate
# Windows:
venv\Scripts\activate

# Instale as dependÃªncias
pip install -r requirements.txt
```
#### 5. **Configure as variÃ¡veis de ambiente**
```bash
# Copie o arquivo de exemplo
cp .env.example .env

# Edite o .env com suas configuraÃ§Ãµes
nano .env  # ou use seu editor preferido
```




## ğŸ“¡ Uso do Endpoint /AgenteMath

### RequisiÃ§Ã£o

```bash
POST /AgenteMath
{
  "message": "Quanto Ã© 20 * (3 + 2)?"
}
```
### Resposta (exemplo)
```bash
{
  "response": "20 * (3 + 2) = 100"
}
```

## ğŸ› ï¸ Estrutura do Projeto

```bash
ğŸ“ app
 â”œâ”€â”€ agent.py        # ConfiguraÃ§Ã£o do Agente de IA
 â”œâ”€â”€ main.py         # API FastAPI
 â””â”€â”€ tools.py        # Tools customizadas (ex.: calculadora)
 
.env
requirements.txt
README.md
.gitignore
run_local.bat
```