# AI Chat API ‚Äî FastAPI + Strands Agents + Ollama

Este projeto implementa uma API de chat integrada com um Agente de IA local,
utilizando o SDK Strands Agents e o modelo Ollama rodando localmente.

O agente possui:
- Conversa√ß√£o geral
- Tool personalizada para c√°lculos matem√°ticos
- Integra√ß√£o com FastAPI

---

## üöÄ Funcionalidades

- Endpoint `/chat` para conversa√ß√£o
- Uso de modelo LLM local pelo Ollama
- Tool matem√°tica que resolve express√µes
- Configura√ß√£o via `.env`
- Respostas r√°pidas via FastAPI + Uvicorn

---

## üß± Requisitos

- Python 3.10+
- Ollama instalado
- Modelo local (ex.: `llama3.1`)

---

## üì¶ Instala√ß√£o

### 1. Instale o Ollama
Baixe em: https://ollama.com

### 2. Baixe o modelo desejado
```bash
ollama pull llama3.1
